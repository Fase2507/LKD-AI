{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a48951-1b9b-4480-b36b-dd62b96695f2",
   "metadata": {
    "panel-layout": {
     "height": 51.15000915527344,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    WEB SCRAPPING\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587387a-51e1-474b-b9c4-36dc3af6ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a1f08-cc08-4ae6-9376-b55b4fb4f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Http/s ayarlari oturum vs\n",
    "BASE_URL='https://quotes.toscrape.com'\n",
    "START_URL=f\"{BASE_URL}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c5b78-17e9-4a24-a4f1-f5038845e9e4",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "session=requests.Session()\n",
    "session.headers.update({\n",
    "    \"user-agent\":\"Welcome to page\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8766a3-d42b-47d0-8e37-40975fcc6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TIMEOUT=10\n",
    "MAX_RETRIES=3\n",
    "BACKOFF_BASE=1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4e040-ad46-4d14-9bdc-9bc1b7b1be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL cekme\n",
    "def fetch(url:str)->Optional[requests.Response]:\n",
    "    for attempt in range(1,MAX_RETRIES+1):\n",
    "        try:\n",
    "            response=session.get(url,timeout=DEFAULT_TIMEOUT)\n",
    "            if response.status_code==200:\n",
    "                return response\n",
    "            else:\n",
    "                print(f\"(UYARI) {url} -> HTTP {response.status_code}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"(HATA) {url} istek hatasi: {e}\")\n",
    "\n",
    "        back_time=BACKOFF_BASE**attempt+random.uniform(0,0.5)\n",
    "        time.sleep(back_time)\n",
    "    print(\"PEsss!!\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6db911-c5e6-42b5-be31-ebb06c2343a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parser yaz\n",
    "def quotes_parser(html:str)->List[Dict]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    results=[]\n",
    "\n",
    "    for quote in soup.select(\"div.quote\"):\n",
    "        text = quote.select_one(\"span.text\")\n",
    "        author=quote.select_one(\"small.author\")\n",
    "        tags=quote.select_one(\"div.tags a.tag\")\n",
    "\n",
    "        results.append({\n",
    "            \"text\":text.get_text(strip=True) if text else \"\",\n",
    "            \"author\": author.get_text(strip=True) if author else \"\",\n",
    "            \"tags\": \",\".join(t.get_text(strip=True) for t in tags) if tags else \"\"\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0daafe43-e4d3-4bff-838a-cee4a8a89824",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=fetch(BASE_URL)\n",
    "result=quotes_parser(res.text)\n",
    "with open(\"quote.txt\",\"a\") as f:\n",
    "    for q in result:\n",
    "        f.write(f'Text {q[\"text\"]}\\nAuthor: {q[\"author\"]}\\nTags: {q[\"tags\"]}\\n{\"-\"*30}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "925f3a70-da7c-48bb-8408-2be4f38f6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_page_url(html:str)->str|None:\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\n",
    "    next_link= soup.select_one(\"li.next>a\")\n",
    "    if not next_link or not next_link.get(\"href\"):\n",
    "            return None\n",
    "    else:\n",
    "        return BASE_URL + next_link.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48af62de-3ad8-4df6-ab31-8b5f652e68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(rows:List[Dict],out_path:Path):\n",
    "    out_path.parent.mkdir(parents=True,exist_ok=True)\n",
    "    fieldnames=[\"text\",\"author\",\"tags\"]\n",
    "    write_header=not out_path.exists()\n",
    "\n",
    "    with out_path.open(\"a\", newline=\"\",encoding=\"utf-8\") as f:\n",
    "        writer=csv.DictWriter(f,fieldnames=fieldnames)\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c59a60a1-f3a0-4049-8cc9-224248e943fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_all(start_url:str=START_URL,out_csv: str='./data/quotes.csv'):\n",
    "    current_url=start_url\n",
    "    csv_path=Path(out_csv)\n",
    "    page_no=1\n",
    "    total=0\n",
    "    print(f\"Veri kazima basladi!!...\")\n",
    "    while current_url:\n",
    "        print(f\"[GET] {page_no} crawling...\")\n",
    "        resp=fetch(current_url)\n",
    "        if resp is None:\n",
    "            print(\"Durdu!!\")\n",
    "            break\n",
    "        quotes=quotes_parser(resp.text)\n",
    "        if quotes:\n",
    "            save_to_csv(quotes,csv_path)\n",
    "            total+=1\n",
    "            print(f'[ok] {page_no} : {len(quotes)} kayir eklendi')\n",
    "        else:\n",
    "            print(\"Uyari burada bir sey yok!!\")\n",
    "        time.sleep(random.uniform(0.8,1.6))\n",
    "\n",
    "        next_url=find_next_page_url(resp.text)\n",
    "        if next_url:\n",
    "            current_url = next_url\n",
    "            page_no += 1\n",
    "        else:\n",
    "            print(\"Bitti\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0bf4c44-ae55-4e26-8886-3425d0092dd2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri kazima basladi!!...\n",
      "[GET] 1 crawling...\n",
      "[ok] 1 : 10 kayir eklendi\n",
      "[GET] 2 crawling...\n",
      "[ok] 2 : 10 kayir eklendi\n",
      "[GET] 3 crawling...\n",
      "[ok] 3 : 10 kayir eklendi\n",
      "[GET] 4 crawling...\n",
      "[ok] 4 : 10 kayir eklendi\n",
      "[GET] 5 crawling...\n",
      "[ok] 5 : 10 kayir eklendi\n",
      "[GET] 6 crawling...\n",
      "[ok] 6 : 10 kayir eklendi\n",
      "[GET] 7 crawling...\n",
      "[ok] 7 : 10 kayir eklendi\n",
      "[GET] 8 crawling...\n",
      "[ok] 8 : 10 kayir eklendi\n",
      "[GET] 9 crawling...\n",
      "[ok] 9 : 10 kayir eklendi\n",
      "[GET] 10 crawling...\n",
      "[ok] 10 : 10 kayir eklendi\n",
      "Bitti\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    crawl_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690feef-e921-42f8-ad12-d728dc2fedec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "panel-cell-order": [
   "46a48951-1b9b-4480-b36b-dd62b96695f2",
   "622c5b78-17e9-4a24-a4f1-f5038845e9e4"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
